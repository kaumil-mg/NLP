{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Dear HR,My name is Kaumil, and I have 4 years of experience as a data analyst. \n",
    "After coming across the job opening for a data analyst at Cybercom on LinkedIn, I believe that I would be a great fit for this position based on the job description. You can also find my web resume here. \n",
    "I have attached my resume for your reference.\n",
    "Regards,\n",
    "Kaumil \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "## Sentences -> paragraph\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear HR,My name is Kaumil, and I have 4 years of experience as a data analyst. \n",
      "After coming across the job opening for a data analyst at Cybercom on LinkedIn, I believe that I would be a great fit for this position based on the job description. You can also find my web resume here. \n",
      "I have attached my resume for your reference.\n",
      "Regards,\n",
      "Kaumil \n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dear',\n",
       " 'HR',\n",
       " ',',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Kaumil',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'have',\n",
       " '4',\n",
       " 'years',\n",
       " 'of',\n",
       " 'experience',\n",
       " 'as',\n",
       " 'a',\n",
       " 'data',\n",
       " 'analyst',\n",
       " '.',\n",
       " 'After',\n",
       " 'coming',\n",
       " 'across',\n",
       " 'the',\n",
       " 'job',\n",
       " 'opening',\n",
       " 'for',\n",
       " 'a',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'at',\n",
       " 'Cybercom',\n",
       " 'on',\n",
       " 'LinkedIn',\n",
       " ',',\n",
       " 'I',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'I',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fit',\n",
       " 'for',\n",
       " 'this',\n",
       " 'position',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'job',\n",
       " 'description',\n",
       " '.',\n",
       " 'You',\n",
       " 'can',\n",
       " 'also',\n",
       " 'find',\n",
       " 'my',\n",
       " 'web',\n",
       " 'resume',\n",
       " 'here',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'attached',\n",
       " 'my',\n",
       " 'resume',\n",
       " 'for',\n",
       " 'your',\n",
       " 'reference',\n",
       " '.',\n",
       " 'Regards',\n",
       " ',',\n",
       " 'Kaumil']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dear', 'HR', ',', 'My', 'name', 'is', 'Kaumil', ',', 'and', 'I', 'have', '4', 'years', 'of', 'experience', 'as', 'a', 'data', 'analyst', '.']\n",
      "['After', 'coming', 'across', 'the', 'job', 'opening', 'for', 'a', 'data', 'analyst', 'at', 'Cybercom', 'on', 'LinkedIn', ',', 'I', 'believe', 'that', 'I', 'would', 'be', 'a', 'great', 'fit', 'for', 'this', 'position', 'based', 'on', 'the', 'job', 'description', '.']\n",
      "['You', 'can', 'also', 'find', 'my', 'web', 'resume', 'here', '.']\n",
      "['I', 'have', 'attached', 'my', 'resume', 'for', 'your', 'reference', '.']\n",
      "['Regards', ',', 'Kaumil']\n"
     ]
    }
   ],
   "source": [
    "for sent1 in docs:\n",
    "    print(word_tokenize(sent1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dear',\n",
       " 'HR',\n",
       " ',',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Kaumil',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'have',\n",
       " '4',\n",
       " 'years',\n",
       " 'of',\n",
       " 'experience',\n",
       " 'as',\n",
       " 'a',\n",
       " 'data',\n",
       " 'analyst',\n",
       " '.',\n",
       " 'After',\n",
       " 'coming',\n",
       " 'across',\n",
       " 'the',\n",
       " 'job',\n",
       " 'opening',\n",
       " 'for',\n",
       " 'a',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'at',\n",
       " 'Cybercom',\n",
       " 'on',\n",
       " 'LinkedIn',\n",
       " ',',\n",
       " 'I',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'I',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fit',\n",
       " 'for',\n",
       " 'this',\n",
       " 'position',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'job',\n",
       " 'description',\n",
       " '.',\n",
       " 'You',\n",
       " 'can',\n",
       " 'also',\n",
       " 'find',\n",
       " 'my',\n",
       " 'web',\n",
       " 'resume',\n",
       " 'here',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'attached',\n",
       " 'my',\n",
       " 'resume',\n",
       " 'for',\n",
       " 'your',\n",
       " 'reference',\n",
       " '.',\n",
       " 'Regards',\n",
       " ',',\n",
       " 'Kaumil']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "corpus=tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming \n",
    "words =  ['eating','eats','eaten','giving','gave','gives','writing','writes','programming','programs','history','histories','finally','finals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porter stemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming =PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear------>dear\n",
      "HR------>hr\n",
      ",------>,\n",
      "My------>my\n",
      "name------>name\n",
      "is------>is\n",
      "Kaumil------>kaumil\n",
      ",------>,\n",
      "and------>and\n",
      "I------>i\n",
      "have------>have\n",
      "4------>4\n",
      "years------>year\n",
      "of------>of\n",
      "experience------>experi\n",
      "as------>as\n",
      "a------>a\n",
      "data------>data\n",
      "analyst.------>analyst.\n",
      "After------>after\n",
      "coming------>come\n",
      "across------>across\n",
      "the------>the\n",
      "job------>job\n",
      "opening------>open\n",
      "for------>for\n",
      "a------>a\n",
      "data------>data\n",
      "analyst------>analyst\n",
      "at------>at\n",
      "Cybercom------>cybercom\n",
      "on------>on\n",
      "LinkedIn------>linkedin\n",
      ",------>,\n",
      "I------>i\n",
      "believe------>believ\n",
      "that------>that\n",
      "I------>i\n",
      "would------>would\n",
      "be------>be\n",
      "a------>a\n",
      "great------>great\n",
      "fit------>fit\n",
      "for------>for\n",
      "this------>thi\n",
      "position------>posit\n",
      "based------>base\n",
      "on------>on\n",
      "the------>the\n",
      "job------>job\n",
      "description.------>description.\n",
      "You------>you\n",
      "can------>can\n",
      "also------>also\n",
      "find------>find\n",
      "my------>my\n",
      "web------>web\n",
      "resume------>resum\n",
      "here.------>here.\n",
      "I------>i\n",
      "have------>have\n",
      "attached------>attach\n",
      "my------>my\n",
      "resume------>resum\n",
      "for------>for\n",
      "your------>your\n",
      "reference.------>reference.\n",
      "Regards------>regard\n",
      ",------>,\n",
      "Kaumil------>kaumil\n"
     ]
    }
   ],
   "source": [
    "for i in corpus:\n",
    "    print(i+\"------>\"+stemming.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegExStemmer class\n",
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-------->eat\n",
      "eats-------->eat\n",
      "eaten-------->eat\n",
      "giving-------->giv\n",
      "gave-------->gave\n",
      "gives-------->give\n",
      "writing-------->writ\n",
      "writes-------->write\n",
      "programming-------->programm\n",
      "programs-------->program\n",
      "history-------->history\n",
      "histories-------->historie\n",
      "finally-------->finally\n",
      "finals-------->final\n"
     ]
    }
   ],
   "source": [
    "reg_stemmer =RegexpStemmer('ing$|s$|en$|able$', min=4)\n",
    "for i in words:\n",
    "    print(i+'-------->'+reg_stemmer.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowball stemmer\n",
    "\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eat\n",
      "eats------>eat\n",
      "eaten------>eaten\n",
      "giving------>give\n",
      "gave------>gave\n",
      "gives------>give\n",
      "writing------>write\n",
      "writes------>write\n",
      "programming------>program\n",
      "programs------>program\n",
      "history------>histori\n",
      "histories------>histori\n",
      "finally------>final\n",
      "finals------>final\n"
     ]
    }
   ],
   "source": [
    "snowball = SnowballStemmer('english')\n",
    "for i in words:\n",
    "    print(i+'------>'+snowball.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmetization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "word : str\n",
    "The input word to lemmatize.\n",
    "\n",
    "pos : str\n",
    "The Part Of Speech tag. Valid options are \"n\" for nouns, \"v\" for verbs, \"a\" for adjectives, \"r\" for adverbs and \"s\" for satellite adjectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fly'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "wordnet.lemmatize('flying',pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-------->eat\n",
      "eats-------->eat\n",
      "eaten-------->eat\n",
      "giving-------->give\n",
      "gave-------->give\n",
      "gives-------->give\n",
      "writing-------->write\n",
      "writes-------->write\n",
      "programming-------->program\n",
      "programs-------->program\n",
      "history-------->history\n",
      "histories-------->histories\n",
      "finally-------->finally\n",
      "finals-------->finals\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(i+'-------->'+wordnet.lemmatize(i,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Stopwords\n",
    "speech =\"\"\"Good day, everyone,\n",
    "\n",
    "Today, I want to share some interesting findings from the analysis of cricket matches over the last three years and how this data can help us predict which teams might win in 2025.\n",
    "\n",
    "What We Learned from the Past Three Years\n",
    "Total Runs and Team Strength: Teams with strong batting lineups have consistently scored high runs. Teams like Sunrisers Hyderabad and Mumbai Indians have been particularly strong, often posting high scores, especially when they win the toss and choose to bat first.\n",
    "\n",
    "The Importance of the Toss: The toss has shown to play a big role in deciding the outcome of a match. Teams that win the toss and choose to bat first tend to perform better, setting higher scores and putting pressure on the other team.\n",
    "\n",
    "Impact of the Venue: The stadium where a match is played also makes a difference. Some grounds, like Eden Gardens and Wankhede Stadium, tend to favor teams with strong batting, leading to higher-scoring matches.\n",
    "\n",
    "What Can We Expect in 2025?\n",
    "With the help of machine learning, we've built a model that looks at all these factors—team strength, toss results, and match venues—to predict which teams are likely to win in 2025. Based on current trends, teams like Chennai Super Kings and Delhi Capitals look promising for the upcoming season.\n",
    "\n",
    "While the data can give us a good idea of what to expect, cricket is full of surprises, and that’s what makes the game so exciting.\n",
    "\n",
    "Thank you!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good day, everyone,\n",
      "\n",
      "Today, I want to share some interesting findings from the analysis of cricket matches over the last three years and how this data can help us predict which teams might win in 2025.\n",
      "\n",
      "What We Learned from the Past Three Years\n",
      "Total Runs and Team Strength: Teams with strong batting lineups have consistently scored high runs. Teams like Sunrisers Hyderabad and Mumbai Indians have been particularly strong, often posting high scores, especially when they win the toss and choose to bat first.\n",
      "\n",
      "The Importance of the Toss: The toss has shown to play a big role in deciding the outcome of a match. Teams that win the toss and choose to bat first tend to perform better, setting higher scores and putting pressure on the other team.\n",
      "\n",
      "Impact of the Venue: The stadium where a match is played also makes a difference. Some grounds, like Eden Gardens and Wankhede Stadium, tend to favor teams with strong batting, leading to higher-scoring matches.\n",
      "\n",
      "What Can We Expect in 2025?\n",
      "With the help of machine learning, we've built a model that looks at all these factors—team strength, toss results, and match venues—to predict which teams are likely to win in 2025. Based on current trends, teams like Chennai Super Kings and Delhi Capitals look promising for the upcoming season.\n",
      "\n",
      "While the data can give us a good idea of what to expect, cricket is full of surprises, and that’s what makes the game so exciting.\n",
      "\n",
      "Thank you!\n"
     ]
    }
   ],
   "source": [
    "print(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "sentences=nltk.sent_tokenize(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good day, everyone,\\n\\nToday, I want to share some interesting findings from the analysis of cricket matches over the last three years and how this data can help us predict which teams might win in 2025.',\n",
       " 'What We Learned from the Past Three Years\\nTotal Runs and Team Strength: Teams with strong batting lineups have consistently scored high runs.',\n",
       " 'Teams like Sunrisers Hyderabad and Mumbai Indians have been particularly strong, often posting high scores, especially when they win the toss and choose to bat first.',\n",
       " 'The Importance of the Toss: The toss has shown to play a big role in deciding the outcome of a match.',\n",
       " 'Teams that win the toss and choose to bat first tend to perform better, setting higher scores and putting pressure on the other team.',\n",
       " 'Impact of the Venue: The stadium where a match is played also makes a difference.',\n",
       " 'Some grounds, like Eden Gardens and Wankhede Stadium, tend to favor teams with strong batting, leading to higher-scoring matches.',\n",
       " 'What Can We Expect in 2025?',\n",
       " \"With the help of machine learning, we've built a model that looks at all these factors—team strength, toss results, and match venues—to predict which teams are likely to win in 2025.\",\n",
       " 'Based on current trends, teams like Chennai Super Kings and Delhi Capitals look promising for the upcoming season.',\n",
       " 'While the data can give us a good idea of what to expect, cricket is full of surprises, and that’s what makes the game so exciting.',\n",
       " 'Thank you!']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Stopwords And Filter And then Apply Stemming\n",
    "sentences=nltk.sent_tokenize(speech)\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i]=' '.join(words)# converting all the list of words into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good day , everyon , today , i want share interest find analysi cricket match last three year data help us predict team might win 2025 .',\n",
       " 'what we learn past three year total run team strength : team strong bat lineup consist score high run .',\n",
       " 'team like sunris hyderabad mumbai indian particular strong , often post high score , especi win toss choos bat first .',\n",
       " 'the import toss : the toss shown play big role decid outcom match .',\n",
       " 'team win toss choos bat first tend perform better , set higher score put pressur team .',\n",
       " 'impact venu : the stadium match play also make differ .',\n",
       " 'some ground , like eden garden wankhed stadium , tend favor team strong bat , lead higher-scor match .',\n",
       " 'what can we expect 2025 ?',\n",
       " 'with help machin learn , ve built model look factors—team strength , toss result , match venues—to predict team like win 2025 .',\n",
       " 'base current trend , team like chennai super king delhi capit look promis upcom season .',\n",
       " 'while data give us good idea expect , cricket full surpris , ’ make game excit .',\n",
       " 'thank !']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Stopwords And Filter And then Apply lemmetizing Stemming\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemme = WordNetLemmatizer()\n",
    "sentences=nltk.sent_tokenize(speech)\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[lemme.lemmatize(word.lower(),pos='v') for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i]=' '.join(words)# converting all the list of words into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good day , everyone , today , i want share interest findings analysis cricket match last three years data help us predict team might win 2025 .',\n",
       " 'what we learn past three years total run team strength : team strong bat lineups consistently score high run .',\n",
       " 'team like sunrisers hyderabad mumbai indians particularly strong , often post high score , especially win toss choose bat first .',\n",
       " 'the importance toss : the toss show play big role decide outcome match .',\n",
       " 'team win toss choose bat first tend perform better , set higher score put pressure team .',\n",
       " 'impact venue : the stadium match play also make difference .',\n",
       " 'some ground , like eden garden wankhede stadium , tend favor team strong bat , lead higher-scoring match .',\n",
       " 'what can we expect 2025 ?',\n",
       " \"with help machine learn , 've build model look factors—team strength , toss result , match venues—to predict team likely win 2025 .\",\n",
       " 'base current trend , team like chennai super kings delhi capitals look promise upcoming season .',\n",
       " 'while data give us good idea expect , cricket full surprise , ’ make game excite .',\n",
       " 'thank !']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Good', 'JJ'),\n",
       " ('day,', 'NN'),\n",
       " ('everyone,', 'IN'),\n",
       " ('Today,', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('share', 'NN'),\n",
       " ('some', 'DT'),\n",
       " ('interesting', 'JJ'),\n",
       " ('findings', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('analysis', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('cricket', 'NN'),\n",
       " ('matches', 'NNS'),\n",
       " ('over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('last', 'JJ'),\n",
       " ('three', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('how', 'WRB'),\n",
       " ('this', 'DT'),\n",
       " ('data', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('help', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('predict', 'VB'),\n",
       " ('which', 'WDT'),\n",
       " ('teams', 'NN'),\n",
       " ('might', 'MD'),\n",
       " ('win', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('2025.', 'CD'),\n",
       " ('What', 'WP'),\n",
       " ('We', 'PRP'),\n",
       " ('Learned', 'VBD'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Past', 'NNP'),\n",
       " ('Three', 'CD'),\n",
       " ('Years', 'NNP'),\n",
       " ('Total', 'NNP'),\n",
       " ('Runs', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Team', 'NNP'),\n",
       " ('Strength:', 'NNP'),\n",
       " ('Teams', 'NNP'),\n",
       " ('with', 'IN'),\n",
       " ('strong', 'JJ'),\n",
       " ('batting', 'VBG'),\n",
       " ('lineups', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('consistently', 'RB'),\n",
       " ('scored', 'VBN'),\n",
       " ('high', 'JJ'),\n",
       " ('runs.', 'NN'),\n",
       " ('Teams', 'NNP'),\n",
       " ('like', 'IN'),\n",
       " ('Sunrisers', 'NNP'),\n",
       " ('Hyderabad', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Mumbai', 'NNP'),\n",
       " ('Indians', 'NNPS'),\n",
       " ('have', 'VBP'),\n",
       " ('been', 'VBN'),\n",
       " ('particularly', 'RB'),\n",
       " ('strong,', 'JJ'),\n",
       " ('often', 'RB'),\n",
       " ('posting', 'VBG'),\n",
       " ('high', 'JJ'),\n",
       " ('scores,', 'NN'),\n",
       " ('especially', 'RB'),\n",
       " ('when', 'WRB'),\n",
       " ('they', 'PRP'),\n",
       " ('win', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('toss', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('choose', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('bat', 'VB'),\n",
       " ('first.', 'VB'),\n",
       " ('The', 'DT'),\n",
       " ('Importance', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Toss:', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('toss', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('shown', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('play', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('role', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('deciding', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('outcome', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('match.', 'JJ'),\n",
       " ('Teams', 'NNP'),\n",
       " ('that', 'WDT'),\n",
       " ('win', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('toss', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('choose', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('bat', 'VB'),\n",
       " ('first', 'JJ'),\n",
       " ('tend', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('perform', 'VB'),\n",
       " ('better,', 'NN'),\n",
       " ('setting', 'VBG'),\n",
       " ('higher', 'JJR'),\n",
       " ('scores', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('putting', 'VBG'),\n",
       " ('pressure', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('other', 'JJ'),\n",
       " ('team.', 'JJ'),\n",
       " ('Impact', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Venue:', 'NNP'),\n",
       " ('The', 'DT'),\n",
       " ('stadium', 'NN'),\n",
       " ('where', 'WRB'),\n",
       " ('a', 'DT'),\n",
       " ('match', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('played', 'VBN'),\n",
       " ('also', 'RB'),\n",
       " ('makes', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('difference.', 'JJ'),\n",
       " ('Some', 'DT'),\n",
       " ('grounds,', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('Eden', 'NNP'),\n",
       " ('Gardens', 'NNPS'),\n",
       " ('and', 'CC'),\n",
       " ('Wankhede', 'NNP'),\n",
       " ('Stadium,', 'NNP'),\n",
       " ('tend', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('favor', 'VB'),\n",
       " ('teams', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('strong', 'JJ'),\n",
       " ('batting,', 'NN'),\n",
       " ('leading', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('higher-scoring', 'JJ'),\n",
       " ('matches.', 'NN'),\n",
       " ('What', 'WP'),\n",
       " ('Can', 'MD'),\n",
       " ('We', 'PRP'),\n",
       " ('Expect', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('2025?', 'CD'),\n",
       " ('With', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('help', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('machine', 'NN'),\n",
       " ('learning,', 'NN'),\n",
       " (\"we've\", 'NN'),\n",
       " ('built', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('model', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('looks', 'VBZ'),\n",
       " ('at', 'IN'),\n",
       " ('all', 'PDT'),\n",
       " ('these', 'DT'),\n",
       " ('factors—team', 'JJ'),\n",
       " ('strength,', 'NN'),\n",
       " ('toss', 'NN'),\n",
       " ('results,', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('match', 'NN'),\n",
       " ('venues—to', 'NN'),\n",
       " ('predict', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('teams', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('likely', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('win', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('2025.', 'CD'),\n",
       " ('Based', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('current', 'JJ'),\n",
       " ('trends,', 'JJ'),\n",
       " ('teams', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('Chennai', 'NNP'),\n",
       " ('Super', 'NNP'),\n",
       " ('Kings', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Delhi', 'NNP'),\n",
       " ('Capitals', 'NNP'),\n",
       " ('look', 'VBP'),\n",
       " ('promising', 'VBG'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('upcoming', 'JJ'),\n",
       " ('season.', 'NN'),\n",
       " ('While', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('data', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('give', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('idea', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('what', 'WP'),\n",
       " ('to', 'TO'),\n",
       " ('expect,', 'VB'),\n",
       " ('cricket', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('full', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('surprises,', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('that’s', 'VB'),\n",
       " ('what', 'WP'),\n",
       " ('makes', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('game', 'NN'),\n",
       " ('so', 'RB'),\n",
       " ('exciting.', 'JJ'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you!', 'NN')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=nltk.sent_tokenize(speech)\n",
    "sent=speech\n",
    "nltk.pos_tag(sent.split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
